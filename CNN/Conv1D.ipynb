{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "from model import CNN1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fingerprint(smiles: str, radius=2, n_bits=2048):\n",
    "    \"\"\"\n",
    "    Converts a list of SMILES strings to ECFP4 fingerprints.\n",
    "\n",
    "    Parameters:\n",
    "        smiles (str): SMILES of a molecule.\n",
    "        radius (int): Radius parameter for Morgan fingerprint. ECFP4 corresponds to radius=2.\n",
    "        n_bits (int): Size of the fingerprint bit vector.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of fingerprint vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    # See other fingerprint generation methods:\n",
    "    # https://www.rdkit.org/docs/GettingStartedInPython.html#fingerprinting-and-molecular-similarity\n",
    "    generator = AllChem.GetMorganGenerator(radius=radius, fpSize=n_bits)\n",
    "    fingerprint = generator.GetFingerprint(mol)\n",
    "    return np.array(fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Training Loop\n",
    "def train_model(model, train_dataloader, val_dataloader, criterion, optimizer, num_epochs=10, device='cuda', weights_path=Path(\"weights\")):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_dataloader:\n",
    "            # Move data to device if using GPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_dataloader):.4f}\")\n",
    "        \n",
    "    gt, pred = validate_model(model, val_dataloader)\n",
    "    val_score = criterion(torch.from_numpy(pred), torch.from_numpy(gt))\n",
    "    torch.save(model.state_dict(), weights_path/f\"model_{num_epochs}_{val_score}.pt\")\n",
    "\n",
    "    \n",
    "\n",
    "def validate_model(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match():\n",
    "    # TODO Pick the batches by least similar molecules\n",
    "    # Create a table where for each molecule we have the least similar molecules\n",
    "    # (e.g. num mcs atoms < (num_mol_atoms*0.3) and num_mcs_bonds < (num_mol_bonds*0.3))\n",
    "    from rdkit.Chem import rdFMCS\n",
    "    from rdkit.Chem import Draw\n",
    "\n",
    "    mol1 = Chem.MolFromSmiles(train['smiles'][0])\n",
    "    closest_by_atoms_mol = None\n",
    "    closest_by_bonds_mol = None\n",
    "    ac = 0\n",
    "    bc = 0\n",
    "    for mol in train['smiles'][1:1000]:\n",
    "        mol2 = Chem.MolFromSmiles(mol)\n",
    "        mcs = rdFMCS.FindMCS([mol1, mol2])\n",
    "        mcs_mol = Chem.MolFromSmarts(mcs.smartsString)\n",
    "        # Draw.MolsToGridImage([mol1, mol2, mcs_mol], molsPerRow=3)\n",
    "        if mcs.numAtoms > ac:\n",
    "            ac = mcs.numAtoms\n",
    "            closest_by_atoms_mol = mcs_mol\n",
    "\n",
    "        if mcs.numBonds > bc:\n",
    "            bc = mcs.numBonds\n",
    "            closest_by_bonds_mol = mcs_mol\n",
    "\n",
    "    Draw.MolsToGridImage([mol1, closest_by_atoms_mol, closest_by_bonds_mol], molsPerRow=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path(\"../data\")\n",
    "weights_path = Path(\"./weights\")\n",
    "train_file_path = data_root / \"train.csv\"\n",
    "test_file_path = data_root / \"test.csv\"\n",
    "output_file_path = data_root / \"submission.csv\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train = pd.read_csv(train_file_path)\n",
    "test = pd.read_csv(test_file_path)\n",
    "submission = test.copy()\n",
    "submission.drop(columns=[\"smiles\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "x_data_file = data_root / \"x_data.pt\"\n",
    "y_data_file = data_root / \"y_data.pt\"\n",
    "if x_data_file.exists() and y_data_file.exists():\n",
    "    x = torch.load(x_data_file, weights_only=True)\n",
    "    y = torch.load(y_data_file, weights_only=True)\n",
    "else:\n",
    "    x = torch.stack([torch.from_numpy(generate_fingerprint(s)).float() for s in train[\"smiles\"]]).unsqueeze(1).to(device)\n",
    "    y = torch.tensor(train[\"activity\"].values).float().to(device)\n",
    "\n",
    "    torch.save(x, x_data_file)\n",
    "    torch.save(y, y_data_file)\n",
    "\n",
    "x_train = x[:int(0.8*len(x))]\n",
    "y_train = y[:int(0.8*len(y))]\n",
    "\n",
    "x_val = x[int(0.8*len(x)):]\n",
    "y_val = y[int(0.8*len(y)):]\n",
    "\n",
    "x_test = torch.stack([torch.from_numpy(generate_fingerprint(s)).float() for s in test[\"smiles\"]]).unsqueeze(1).to(device)\n",
    "y_test = torch.zeros(len(x_test), device=device).float()\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1024])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_dataloader, val_dataloader, criterion, optimizer, num_epochs, device, weights_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[0;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\yanek\\anaconda3\\envs\\bioml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yanek\\anaconda3\\envs\\bioml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\yanek\\anaconda3\\envs\\bioml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:697\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yanek\\anaconda3\\envs\\bioml\\lib\\site-packages\\torch\\nn\\functional.py:3545\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3543\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[1;32m-> 3545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3546\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3547\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3548\u001b[0m     )\n\u001b[0;32m   3550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3551\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1024])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "# Model, criterion and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN1D().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.1)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_dataloader, val_dataloader, criterion, optimizer, num_epochs=num_epochs, weights_path=weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8965)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8072797151032477"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt, pred = validate_model(model, val_dataloader)\n",
    "print(criterion(torch.from_numpy(pred), torch.from_numpy(gt)))\n",
    "pred[pred>=0.5] = 1\n",
    "pred[pred<0.5] = 0\n",
    "average_precision_score(gt, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt, pred = validate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"activity\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          CNC[C@H](c1ccc(Cl)c(Cl)c1)[C@@H](O)c1cccc(N)c1\n",
       "1       C[C@@H]1Cn2ncc(C3CCN(S(C)(=O)=O)CC3)c2CN1c1ccn...\n",
       "2       CNC(=O)c1c(NCC2CCC3(CCCC3)CC2)nc(C#N)nc1OCC1CC...\n",
       "3                 Cc1cc(CNc2nc(N)nc3ccn(Cc4ccccn4)c23)no1\n",
       "4           C[C@@]1(c2cc(CNCCC(F)(F)F)c(F)cc2F)CCSC(N)=N1\n",
       "                              ...                        \n",
       "4211    O=C1COc2ccc(CNC34CCC(CCc5c(F)cnc6ccc(OC[C@@H]7...\n",
       "4212    CCc1ccc([C@H](CCN2C3CCC2CC(n2c(C)nnc2C(C)C)C3)...\n",
       "4213          COc1cccc(-c2c(C(=O)N3CCCCC3CO)cc3ccccn23)c1\n",
       "4214                      Cc1nncn1Cc1cn(-c2ccc(Cl)cc2)nn1\n",
       "4215    CN(CCCC(=O)NCCO)C(=O)c1ccc2c(c1)c1c(n2C)CC[C@@...\n",
       "Name: smiles, Length: 4216, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>smiles</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cc1ccc2c(N3CCN(CCc4cccc(N5CCNC5=O)c4)CC3)cccc2n1</td>\n",
       "      <td>0.939124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>COc1ccc(Oc2ccc(S(=O)(=O)C3(C(=O)NO)CCC4(CCNCC4...</td>\n",
       "      <td>0.058076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CN1Cc2ccc(-c3ccc(C[C@@H](C#N)NC(=O)C4(N)CCOCC4...</td>\n",
       "      <td>0.003415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>O=C(NC1CC1c1ccccc1)N1CCC(c2ncon2)CC1</td>\n",
       "      <td>0.360064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CNc1cc(CCN2CCN(CCc3ccc4c(c3)COC4=O)CC2)ccc1C#N</td>\n",
       "      <td>0.997569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             smiles  activity\n",
       "0   0   Cc1ccc2c(N3CCN(CCc4cccc(N5CCNC5=O)c4)CC3)cccc2n1  0.939124\n",
       "1   1  COc1ccc(Oc2ccc(S(=O)(=O)C3(C(=O)NO)CCC4(CCNCC4...  0.058076\n",
       "2   2  CN1Cc2ccc(-c3ccc(C[C@@H](C#N)NC(=O)C4(N)CCOCC4...  0.003415\n",
       "3   3               O=C(NC1CC1c1ccccc1)N1CCC(c2ncon2)CC1  0.360064\n",
       "4   4     CNc1cc(CCN2CCN(CCc3ccc4c(c3)COC4=O)CC2)ccc1C#N  0.997569"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
